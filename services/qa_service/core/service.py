import time
import logging
from typing import Dict, Any, Optional

from .config import QAConfig
from .models import QARequest, QAResponse, UserSession
from .exceptions import QAServiceError, LLMError, VectorStoreError, ConfigError
from ..providers.base import LLMProvider, VectorStoreProvider
# ä½¿ç”¨çµ±ä¸€çš„ model_service æ›¿ä»£åˆ†æ•£çš„ providers
from ..providers.vectorstore_provider import ChromaVectorStoreProvider

logger = logging.getLogger(__name__)

class SessionManager:
    """æœƒè©±ç®¡ç†å™¨ - æ¶ˆé™¤å…¨å±€å­—å…¸"""

    def __init__(self, max_sessions: int = 100):
        self._sessions: Dict[str, UserSession] = {}
        self._max_sessions = max_sessions

    def get_session(self, platform: str, user_id: str) -> UserSession:
        """ç²å–æˆ–å‰µå»ºç”¨æˆ¶æœƒè©±"""
        session_key = f"{platform}:{user_id}"

        if session_key not in self._sessions:
            # å¦‚æœæœƒè©±æ•¸é‡éå¤šï¼Œæ¸…ç†èˆŠæœƒè©±
            if len(self._sessions) >= self._max_sessions:
                self._cleanup_old_sessions()

            self._sessions[session_key] = UserSession(
                user_id=user_id,
                platform=platform
            )

        return self._sessions[session_key]

    def _cleanup_old_sessions(self):
        """æ¸…ç†æœ€èˆŠçš„æœƒè©±"""
        if not self._sessions:
            return

        # æ‰¾åˆ°æœ€èˆŠçš„æœƒè©±ä¸¦ç§»é™¤
        oldest_key = min(self._sessions.keys(),
                        key=lambda k: self._sessions[k].last_activity)
        del self._sessions[oldest_key]
        logger.info(f"æ¸…ç†èˆŠæœƒè©±: {oldest_key}")

class QAService:
    """QAæœå‹™æ ¸å¿ƒé¡ - çµ±ä¸€LLMæä¾›å•†æ¶æ§‹"""

    def __init__(self):
        self.model_service = None  # çµ±ä¸€ model_service
        self.vectorstore_provider: Optional[VectorStoreProvider] = None
        self.session_manager = SessionManager()
        self._initialize_providers()

    def _initialize_providers(self):
        """åˆå§‹åŒ–æä¾›å•†"""
        try:
            # ä½¿ç”¨çµ±ä¸€çš„ model_service æ›¿ä»£è‡ªå®šç¾© LLM providers
            from services.model_service import create_model_service
            self.model_service = create_model_service()

            # åˆå§‹åŒ–å‘é‡å­˜å„²æä¾›å•†
            self.vectorstore_provider = ChromaVectorStoreProvider()

            logger.info("QA Service providers initialized successfully with unified model_service")

        except Exception as e:
            logger.error(f"Failed to initialize QA Service providers: {e}")
            raise ConfigError(f"QAæœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")

    async def _generate_answer_with_model_service(self, question: str, context: str, chat_history: list) -> Dict[str, Any]:
        """ä½¿ç”¨çµ±ä¸€ model_service ç”Ÿæˆç­”æ¡ˆ - è‡ªå‹• fallback"""
        try:
            # æ§‹å»ºæç¤º
            if context == "ç„¡éœ€åƒè€ƒæ–‡æª”":
                # ç°¡å–®å•é¡Œä½¿ç”¨ç²¾ç°¡æç¤º
                prompt = QAConfig.SIMPLE_PROMPT
            else:
                # è²¡å‹™å•é¡Œä½¿ç”¨å®Œæ•´æç¤º
                prompt = QAConfig.SYSTEM_PROMPT.format(context=context)

            # æ§‹å»ºæ¨™æº–çš„ messages æ ¼å¼
            messages = [{"role": "system", "content": prompt}]

            # æ·»åŠ å°è©±æ­·å²
            for q, a in chat_history:
                messages.append({"role": "user", "content": q})
                messages.append({"role": "assistant", "content": a})

            # æ·»åŠ ç•¶å‰å•é¡Œ
            messages.append({"role": "user", "content": question})

            # èª¿ç”¨çµ±ä¸€ model_service (è‡ªå‹• fallback)
            response = await self.model_service.qa_completion(messages)

            return {
                "answer": response.content,
                "model": response.model_name,
                "provider": response.provider.value,
                "tokens": {
                    "total": response.usage.total_tokens,
                    "prompt": response.usage.prompt_tokens,
                    "completion": response.usage.completion_tokens
                },
                "cost": response.usage.estimated_cost
            }

        except Exception as e:
            logger.error(f"Model service ç”Ÿæˆç­”æ¡ˆå¤±æ•—: {e}")
            raise LLMError(f"AI ç”Ÿæˆç­”æ¡ˆå¤±æ•—: {e}")

    async def ask(self, request: QARequest) -> QAResponse:
        """è™•ç†QAè«‹æ±‚ - å„ªåŒ–çš„æ™ºèƒ½è·¯ç”±æ¥å£"""
        start_time = time.time()

        try:
            # æª¢æŸ¥æœå‹™å¯ç”¨æ€§
            if not self.model_service:
                raise QAServiceError("Model service æœªåˆå§‹åŒ–")

            # ç²å–ç”¨æˆ¶æœƒè©±
            session = self.session_manager.get_session(request.platform, request.user_id)

            # æ™ºèƒ½å•é¡Œåˆ†é¡ - è€ƒæ…®æœƒè©±ä¸Šä¸‹æ–‡
            question_type = self._classify_question_with_context(request.question, session)

            if question_type == "simple":
                # å¿«é€Ÿè·¯å¾‘ï¼šç°¡å–®å•é¡Œä¸éœ€è¦æœç´¢æ–‡æª”
                context = "ç„¡éœ€åƒè€ƒæ–‡æª”"
                sources = []
                logger.info(f"ä½¿ç”¨å¿«é€Ÿè·¯å¾‘è™•ç†ç°¡å–®å•é¡Œ: {request.question[:30]}...")
            else:
                # æ¨™æº–è·¯å¾‘ï¼šä¸€æ¬¡æ€§ç²å–æ–‡æª”å’Œä¾†æº (é¿å…é‡è¤‡æœç´¢)
                documents = await self._search_documents_once(request.question)
                context = self._format_context(documents)
                sources = self._extract_sources_from_docs(documents)

            # ç”Ÿæˆç­”æ¡ˆ - ä½¿ç”¨çµ±ä¸€ model_service (è‡ªå‹• fallback)
            llm_response = await self._generate_answer_with_model_service(
                request.question, context, session.get_recent_history(3)
            )

            # æ›´æ–°æœƒè©±æ­·å²
            session.add_interaction(request.question, llm_response["answer"])

            # è¨ˆç®—è™•ç†æ™‚é–“
            duration = time.time() - start_time

            # æ§‹å»ºå›æ‡‰
            response = QAResponse(
                answer=self._format_answer(llm_response["answer"], sources),
                sources=sources,
                duration=duration,
                cost=llm_response.get("cost", 0.0),
                total_tokens=llm_response.get("tokens", {}).get("total", 0),
                prompt_tokens=llm_response.get("tokens", {}).get("prompt", 0),
                completion_tokens=llm_response.get("tokens", {}).get("completion", 0)
            )

            logger.info(f"QAè«‹æ±‚è™•ç†å®Œæˆ - ç”¨æˆ¶: {request.user_id}, é¡å‹: {question_type}, è€—æ™‚: {duration:.2f}s")
            return response

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"QAè«‹æ±‚è™•ç†å¤±æ•—: {e}")

            return QAResponse(
                answer=f"æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                sources=[],
                duration=duration
            )

    async def _retrieve_context(self, question: str) -> str:
        """æª¢ç´¢ç›¸é—œä¸Šä¸‹æ–‡"""
        if not self.vectorstore_provider or not self.vectorstore_provider.is_available():
            return "æš«ç„¡å¯ç”¨çš„çŸ¥è­˜åº«å…§å®¹ã€‚"

        try:
            documents = await self.vectorstore_provider.search_documents(
                question, k=QAConfig.TOP_K_SOURCES * 2
            )

            if not documents:
                return "æœªæ‰¾åˆ°ç›¸é—œçš„çŸ¥è­˜åº«å…§å®¹ã€‚"

            # çµ„åˆæ–‡æª”å…§å®¹
            context_parts = []
            for i, doc in enumerate(documents[:QAConfig.TOP_K_SOURCES], 1):
                context_parts.append(f"æ–‡æª”{i}: {doc.content[:500]}...")

            return "\n\n".join(context_parts)

        except Exception as e:
            logger.error(f"æª¢ç´¢ä¸Šä¸‹æ–‡å¤±æ•—: {e}")
            return "æª¢ç´¢çŸ¥è­˜åº«æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"

    async def _extract_sources(self, question: str) -> list:
        """æå–ä¾†æºä¿¡æ¯"""
        if not self.vectorstore_provider or not self.vectorstore_provider.is_available():
            return []

        try:
            documents = await self.vectorstore_provider.search_documents(
                question, k=QAConfig.TOP_K_SOURCES
            )

            sources = []
            for doc in documents:
                source = doc.source
                if source and source not in sources:
                    sources.append(source)

            return sources[:QAConfig.TOP_K_SOURCES]

        except Exception as e:
            logger.error(f"æå–ä¾†æºå¤±æ•—: {e}")
            return []

    def _format_answer(self, answer: str, sources: list) -> str:
        """æ ¼å¼åŒ–ç­”æ¡ˆ - è¦ªåˆ‡é¡§å•é¢¨æ ¼"""
        # æ¸…ç†markdownç¬¦è™Ÿ
        formatted_answer = self._clean_markdown(answer)

        # ç§»é™¤emojiéå¤šçš„æƒ…æ³ï¼Œä¿æŒå°ˆæ¥­ä½†è¦ªåˆ‡
        formatted_answer = self._clean_excessive_emojis(formatted_answer)

        # æ·»åŠ ç°¡æ½”çš„ä¾†æºä¿¡æ¯ï¼ˆç”¨æ›´è¦ªåˆ‡çš„èªæ°£ï¼‰
        if sources:
            sources_text = "\n\nä»¥ä¸Šè³‡è¨Šä¸»è¦åƒè€ƒï¼š\n"
            for i, source in enumerate(sources[:2], 1):  # åªé¡¯ç¤ºå‰2å€‹ä¾†æº
                clean_source = self._clean_source_name(source)
                sources_text += f"â€¢ {clean_source}\n"
            formatted_answer += sources_text

        return formatted_answer

    def _clean_markdown(self, text: str) -> str:
        """æ¸…ç†markdownç¬¦è™Ÿ"""
        import re

        # ç§»é™¤markdownç¬¦è™Ÿ
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # **ç²—é«”**
        text = re.sub(r'\*(.*?)\*', r'\1', text)      # *æ–œé«”*
        text = re.sub(r'#{1,6}\s*', '', text)         # # æ¨™é¡Œ
        text = re.sub(r'`(.*?)`', r'\1', text)        # `ä»£ç¢¼`
        text = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', text)  # [é€£çµ](url)

        # æ¸…ç†å¤šé¤˜ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)

        return text.strip()

    def _clean_source_name(self, source: str) -> str:
        """ç°¡åŒ–ä¾†æºåç¨±"""
        # ç§»é™¤è·¯å¾‘å’Œæ“´å±•å
        import os
        clean_name = os.path.basename(source)
        if clean_name.endswith('.pdf'):
            clean_name = clean_name[:-4]

        # æˆªæ–·éé•·çš„æ–‡ä»¶å
        if len(clean_name) > 30:
            clean_name = clean_name[:27] + "..."

        return clean_name

    def _clean_excessive_emojis(self, text: str) -> str:
        """æ¸…ç†éå¤šçš„emojiï¼Œä¿æŒå°ˆæ¥­ä½†è¦ªåˆ‡çš„é¢¨æ ¼"""
        import re

        # ç§»é™¤é€£çºŒçš„emojiï¼ˆä¿ç•™å–®å€‹emojiï¼‰
        text = re.sub(r'[ğŸ¯ğŸ“‹ğŸ’¡ğŸ“šğŸ’°ğŸ“Šâš ï¸ğŸ”âœ…âŒ]{3,}', '', text)

        # ç§»é™¤è¡Œé¦–çš„emojiæ¨™è¨˜ç¬¦è™Ÿï¼ˆå¦‚ ğŸ¯ã€ğŸ“‹ç­‰ï¼‰ï¼Œä½†ä¿ç•™å…§å®¹ä¸­çš„é©ç•¶emoji
        text = re.sub(r'^[ğŸ¯ğŸ“‹ğŸ’¡ğŸ“šğŸ’°ğŸ“Šâš ï¸ğŸ”âœ…âŒ]\s*', '', text, flags=re.MULTILINE)

        # ä¿ç•™ä¸€äº›æœ‰ç”¨çš„emojiï¼Œä½†é™åˆ¶æ•¸é‡
        useful_emojis = ['ğŸ’°', 'ğŸ“Š', 'âš ï¸', 'âœ…', 'âŒ']
        for emoji in useful_emojis:
            # é™åˆ¶æ¯ç¨®emojiæœ€å¤šå‡ºç¾2æ¬¡
            parts = text.split(emoji)
            if len(parts) > 3:  # è¶…é2æ¬¡å‡ºç¾
                text = emoji.join(parts[:3]) + ''.join(parts[3:])

        return text

    def _classify_question(self, question: str) -> str:
        """å¿«é€Ÿå•é¡Œåˆ†é¡ - åˆ¤æ–·æ˜¯å¦éœ€è¦æœç´¢æ–‡æª”"""
        question_lower = question.lower().strip()

        # ç°¡å–®å•é¡Œæ¨¡å¼ - ä¸éœ€è¦æœç´¢è²¡å‹™æ–‡æª”
        simple_patterns = [
            # è‡ªæˆ‘ä»‹ç´¹é¡
            "ä½ æ˜¯èª°", "ä½ æ˜¯ä»€éº¼", "ä»‹ç´¹ä¸€ä¸‹", "è‡ªæˆ‘ä»‹ç´¹",
            # æ‰“æ‹›å‘¼é¡
            "ä½ å¥½", "å“ˆå›‰", "å—¨", "hi", "hello",
            # åŠŸèƒ½è©¢å•é¡
            "ä½ èƒ½åšä»€éº¼", "ä½ æœƒä»€éº¼", "æœ‰ä»€éº¼åŠŸèƒ½", "æ€éº¼ä½¿ç”¨",
            # æ¸¬è©¦é¡
            "æ¸¬è©¦", "test", "æª¢æŸ¥", "ç¢ºèª"
        ]

        # æª¢æŸ¥æ˜¯å¦ç‚ºç°¡å–®å•é¡Œ
        for pattern in simple_patterns:
            if pattern in question_lower:
                return "simple"

        # çŸ­å•é¡Œä¸”ä¸åŒ…å«è²¡å‹™é—œéµå­—ï¼Œå¯èƒ½æ˜¯ç°¡å–®å•é¡Œ
        if len(question.strip()) <= 10:
            finance_keywords = ["ç¨…", "è²¡å‹™", "æœƒè¨ˆ", "ç™¼ç¥¨", "æ‰£é™¤", "ç”³å ±", "ç‡Ÿæ¥­", "æ‰€å¾—"]
            if not any(keyword in question for keyword in finance_keywords):
                return "simple"

        return "finance"  # éœ€è¦æœç´¢è²¡å‹™æ–‡æª”

    def _classify_question_with_context(self, question: str, session) -> str:
        """å¸¶æœƒè©±ä¸Šä¸‹æ–‡çš„å•é¡Œåˆ†é¡"""
        question_lower = question.lower().strip()

        # ç²å–æœ€è¿‘çš„å°è©±æ­·å²
        recent_history = session.get_recent_history(2)

        # è·Ÿé€²å•é¡Œæ¨¡å¼ - åŸºæ–¼æœƒè©±ä¸Šä¸‹æ–‡åˆ¤æ–·
        followup_patterns = [
            "é‚£", "é€™æ¨£", "æ‰€ä»¥", "å¦‚æœ", "é‚£éº¼", "é‚„æœ‰", "å¦å¤–",
            "è©³ç´°", "å…·é«”", "æ€éº¼", "å¦‚ä½•", "æ­¥é©Ÿ", "æµç¨‹"
        ]

        # å¦‚æœæœ‰å°è©±æ­·å²ä¸”ç•¶å‰å•é¡Œåƒæ˜¯è·Ÿé€²å•é¡Œ
        if recent_history and any(pattern in question_lower for pattern in followup_patterns):
            # æª¢æŸ¥ä¸Šä¸€å€‹å•ç­”æ˜¯å¦æ¶‰åŠè²¡å‹™
            last_question, last_answer = recent_history[-1]
            if any(keyword in last_question.lower() or keyword in last_answer.lower()
                   for keyword in ["ç¨…", "è²¡å‹™", "æœƒè¨ˆ", "ç™¼ç¥¨", "æ‰£é™¤", "ç”³å ±"]):
                return "finance"  # è²¡å‹™ç›¸é—œçš„è·Ÿé€²å•é¡Œ

        # å¦å‰‡ä½¿ç”¨æ¨™æº–åˆ†é¡
        return self._classify_question(question)

    async def _search_documents_once(self, question: str) -> list:
        """ä¸€æ¬¡æ€§æ–‡æª”æœç´¢ - é¿å…é‡è¤‡æœç´¢"""
        if not self.vectorstore_provider or not self.vectorstore_provider.is_available():
            return []

        try:
            documents = await self.vectorstore_provider.search_documents(
                question, k=QAConfig.TOP_K_SOURCES * 2
            )
            return documents or []
        except Exception as e:
            logger.error(f"æ–‡æª”æœç´¢å¤±æ•—: {e}")
            return []

    def _format_context(self, documents: list) -> str:
        """å¾æ–‡æª”åˆ—è¡¨æ ¼å¼åŒ–ä¸Šä¸‹æ–‡"""
        if not documents:
            return "æœªæ‰¾åˆ°ç›¸é—œçš„çŸ¥è­˜åº«å…§å®¹ã€‚"

        context_parts = []
        for i, doc in enumerate(documents[:QAConfig.TOP_K_SOURCES], 1):
            context_parts.append(f"æ–‡æª”{i}: {doc.content[:500]}...")

        return "\n\n".join(context_parts)

    def _extract_sources_from_docs(self, documents: list) -> list:
        """å¾å·²æœç´¢çš„æ–‡æª”ä¸­æå–ä¾†æº"""
        sources = []
        for doc in documents[:QAConfig.TOP_K_SOURCES]:
            source = doc.source
            if source and source not in sources:
                sources.append(source)
        return sources

    def get_service_status(self) -> Dict[str, Any]:
        """ç²å–æœå‹™ç‹€æ…‹"""
        return {
            "model_service": "unified_model_service" if self.model_service else None,
            "vectorstore_available": self.vectorstore_provider.is_available() if self.vectorstore_provider else False,
            "vectorstore_stats": self.vectorstore_provider.get_stats() if self.vectorstore_provider else {},
            "active_sessions": len(self.session_manager._sessions),
            "config": QAConfig.get_llm_config()
        }