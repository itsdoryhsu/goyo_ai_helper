import os
import sys

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„æ·»åŠ åˆ° sys.path
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, PROJECT_ROOT)

import logging
import asyncio
from typing import Dict, Any, Optional, List
import re

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
import time
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
# å°å…¥æœå‹™å’Œå·¥å…·
from services.invoice_service.services.spreadsheet_service import SpreadsheetService
from services.qa_service.qa_client import process_qa_query, init_qa_chain
from services.finance_analysis_service.utils.knowledge_base import get_financial_definitions
import pandas as pd

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, '.env'))

# è¨­ç½®æ—¥èªŒ
LOGS_DIR = os.path.join(PROJECT_ROOT, 'logs')
os.makedirs(LOGS_DIR, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(LOGS_DIR, "finance_analysis_service.log")),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–OpenAI APIå¯†é‘°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if OPENAI_API_KEY:
    os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
    logger.info(f"OPENAI_API_KEY å·²è¨­ç½®: {OPENAI_API_KEY[:5]}...")
else:
    logger.warning("OPENAI_API_KEY æœªè¨­ç½®")

# ç³»çµ±æç¤º
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½èª æ‡‡åˆå°ˆæ¥­çš„è²¡å‹™åˆ†æå¸«å¤¥ä¼´ï¼Œä½ çš„ç›®æ¨™æ˜¯å¹«åŠ©ä½¿ç”¨è€…æ¸…æ™°ã€ç„¡å£“åŠ›åœ°ç†è§£ä»–å€‘çš„è²¡å‹™ç‹€æ³ã€‚

**ä½ çš„æ ¸å¿ƒåŸå‰‡ï¼š**
- **èª å¯¦ä½†æº«æš–**ï¼šåƒä¸€å€‹çœŸæ­£çš„æœ‹å‹ä¸€æ¨£ï¼Œç”¨æœ‰åŒç†å¿ƒçš„èªæ°£ç›´æ¥èªªå¯¦è©±ã€‚é»å‡ºå•é¡Œï¼Œä½†åŒæ™‚çµ¦äºˆæ”¯æŒå’Œé¼“å‹µã€‚
- **æ¸…æ™°çµæ§‹åŒ–**ï¼šè®“è¤‡é›œçš„è²¡å‹™æ•¸æ“šè®Šå¾—ç°¡å–®ã€æ˜“æ–¼æ¶ˆåŒ–ã€‚

**ä½ çš„ä»»å‹™æµç¨‹ï¼š**
1.  **ç†è§£å•é¡Œ**ï¼šåƒæœ‹å‹ä¸€æ¨£ï¼Œå…ˆç†è§£ç”¨æˆ¶æƒ³çŸ¥é“ä»€éº¼ã€‚
2.  **ä½¿ç”¨å·¥å…·**ï¼šåœ¨å¹•å¾Œä½¿ç”¨ pandas å·¥å…·é€²è¡Œç²¾æº–çš„æ•¸æ“šåˆ†æã€‚
3.  **åƒè€ƒçŸ¥è­˜åº«**ï¼šåš´æ ¼éµå®ˆã€Œå•†æ¥­è¦å‰‡ã€å’Œã€Œè²¡å‹™æŒ‡æ¨™è¨ˆç®—æŒ‡å—ã€ã€‚
4.  **ç”Ÿæˆå ±å‘Š**ï¼šç”Ÿæˆä¸€ä»½åŒ…å«ä»¥ä¸‹çµæ§‹çš„æ¸…æ™°å ±å‘Šï¼š
    *   **âœ¨ æ ¸å¿ƒç™¼ç¾**ï¼šä¸€å¥è©±é»å‡ºæœ¬æ¬¡åˆ†ææœ€é—œéµçš„è²¡å‹™åˆ†æinsightã€‚
    *   **ğŸ“Š é—œéµæ•¸å­—**ï¼šç”¨æ¸…æ™°çš„æ¢åˆ—å¼æˆ– Markdown è¡¨æ ¼ï¼Œåˆ—å‡ºæ”¯æŒæ ¸å¿ƒç™¼ç¾çš„é—œéµæ•¸æ“šã€‚
    *   **ğŸ” è¡Œå‹•å»ºè­°**ï¼šæä¾›1-2å€‹å…·é«”ã€å¯è¡Œçš„ä¸‹ä¸€æ­¥å»ºè­°ã€‚
5.  **èªè¨€é¢¨æ ¼**ï¼šä½¿ç”¨**ç¹é«”ä¸­æ–‡**ï¼Œé¢¨æ ¼è¦**èª æ‡‡ã€æ¸…æ™°ã€æœ‰åŒç†å¿ƒ**ã€‚
6.  **å·¥å…·ä½¿ç”¨è¦å‰‡ (***è«‹åš´æ ¼éµå®ˆ***)ï¼š**
    *   **`python_repl_ast` æ˜¯ä½ å”¯ä¸€å¯ä»¥å’Œ `df` äº’å‹•çš„å·¥å…·ã€‚**
    *   **æ‰€æœ‰**å° `df` é€™å€‹ DataFrame çš„æ“ä½œï¼ˆä¾‹å¦‚æŸ¥è©¢ `df[...]`ã€ç¯©é¸ `df.query(...)`ã€è¨ˆç®— `df.sum()` ç­‰ï¼‰ï¼Œéƒ½**å¿…é ˆ**ä½œç‚º `Action Input` å‚³éçµ¦ `python_repl_ast` å·¥å…·ã€‚
    *   ä½ çš„ `Action Input` **åªèƒ½æ˜¯**ä¸€è¡Œç´”ç²¹çš„ Python ç¨‹å¼ç¢¼ï¼Œ**çµ•å°ä¸èƒ½**åŒ…å« `print()` æˆ–ä»»ä½•é Python èªæ³•ã€‚
"""

# æ¨¡å‹å’Œåƒæ•¸è¨­ç½®
DEFAULT_MODEL = "gpt-4.1" # å»ºè­°ä½¿ç”¨æ›´å¼·å¤§çš„æ¨¡å‹é€²è¡Œè²¡å‹™åˆ†æ
DEFAULT_TEMPERATURE = 0.01

# ç”¨æˆ¶æœƒè©±è¨˜æ†¶å’Œè¨­ç½®
user_sessions = {}

class FinanceAnalysisProcessor:
    def __init__(self):
        self.llm = ChatOpenAI(temperature=DEFAULT_TEMPERATURE, model=DEFAULT_MODEL)
        self.spreadsheet_service = SpreadsheetService()
        init_qa_chain()
        logger.info("FinanceAnalysisProcessor åˆå§‹åŒ–æˆåŠŸ")

    def get_user_session(self, platform: str, user_id: str):
        session_key = f"{platform}:{user_id}"
        if session_key not in user_sessions:
            user_sessions[session_key] = {
                "chat_history": [],
                "analysis_data_df": None,
                "memory": ConversationBufferMemory(memory_key="chat_history", return_messages=True)
            }
        return user_sessions[session_key]

    async def _get_spreadsheet_data(self, spreadsheet_url: str) -> Optional[pd.DataFrame]:
        try:
            logger.info(f"æ­£åœ¨å¾ URL è®€å–è©¦ç®—è¡¨æ•¸æ“š: {spreadsheet_url}")
            df = self.spreadsheet_service.read_spreadsheet(spreadsheet_url)
            if df is not None:
                logger.info(f"æˆåŠŸè®€å–è©¦ç®—è¡¨æ•¸æ“šï¼Œå…± {len(df)} è¡Œã€‚")
                return df
            return None
        except Exception as e:
            logger.error(f"è®€å–è©¦ç®—è¡¨æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None

    async def process_finance_query(self, platform: str, user_id: str, query: str) -> Dict[str, Any]:
        start_time = time.time()
        duration = 0
        session = self.get_user_session(platform, user_id)
        analysis_data_df = session.get("analysis_data_df")
        memory = session["memory"]
        response_message = ""
        status = "success"
        total_tokens, prompt_tokens, completion_tokens = 0, 0, 0

        # æ­¥é©Ÿ 1: è¼‰å…¥æˆ–æ›´æ–°è²¡å‹™æ•¸æ“š (åƒ…åœ¨ session ä¸­æ²’æœ‰æ•¸æ“šæ™‚åŸ·è¡Œ)
        if analysis_data_df is None:
            spreadsheet_url = os.getenv("SPREADSHEET_URL")
            spreadsheet_name = os.getenv("SPREADSHEET_NAME")
            
            if spreadsheet_url:
                new_df = await self._get_spreadsheet_data(spreadsheet_url)
            elif spreadsheet_name:
                new_df = self.spreadsheet_service.read_spreadsheet_by_name(spreadsheet_name)
            else:
                new_df = None

            if new_df is not None:
                session["analysis_data_df"] = new_df
                analysis_data_df = new_df
                response_message += "å·²æˆåŠŸè¼‰å…¥é è¨­è©¦ç®—è¡¨æ•¸æ“šã€‚\n"
                memory.clear()  # é¦–æ¬¡è¼‰å…¥æ•¸æ“šï¼Œæ¸…ç©ºè¨˜æ†¶
                logger.info(f"ç”¨æˆ¶ {user_id} é¦–æ¬¡è¼‰å…¥æ•¸æ“šï¼Œè¨˜æ†¶å·²æ¸…ç©ºã€‚")
            else:
                return {"response": "éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°é è¨­çš„è©¦ç®—è¡¨ URL æˆ–åç¨±ï¼Œè«‹æª¢æŸ¥ .env è¨­å®šã€‚", "status": "error"}

        if analysis_data_df is None:
             return {"response": "éŒ¯èª¤ï¼šç„¡æ³•è¼‰å…¥è©¦ç®—è¡¨æ•¸æ“šã€‚", "status": "error"}

        # æ­¥é©Ÿ 2: ç²å–æ¦‚å¿µæ€§çŸ¥è­˜
        professional_query = any(keyword in query for keyword in ["æ˜¯ä»€éº¼", "å¦‚ä½•", "ç‚ºä»€éº¼", "ç¨…æ³•", "æœƒè¨ˆ", "æç›Šè¡¨", "ç¾é‡‘æµé‡è¡¨", "è²¡å‹™å ±è¡¨", "è³‡ç”¢è² å‚µè¡¨"])
        qa_knowledge = ""
        if professional_query:
            qa_response = await process_qa_query(platform, user_id, query)
            qa_knowledge = qa_response['response'].split('---')[0].strip()
            total_tokens += qa_response.get('total_tokens', 0)
            prompt_tokens += qa_response.get('prompt_tokens', 0)
            completion_tokens += qa_response.get('completion_tokens', 0)

        # æ­¥é©Ÿ 3: æº–å‚™æ•¸æ“šä¸¦å»ºç«‹ Pandas DataFrame Agent
        
        # æ ¹æ“šç”¨æˆ¶è¦æ±‚ï¼Œåƒ…é¸æ“‡ç‰¹å®šæ¬„ä½é€²è¡Œåˆ†æ
        required_columns = ["å¸³è™Ÿåç¨±", "é …ç›®", "å“é …", "ç™¼ç¥¨æ—¥æœŸ", "ç™¼ç¥¨é‡‘é¡"]
        available_columns = analysis_data_df.columns.tolist()
        columns_to_use = [col for col in required_columns if col in available_columns]
        
        if not columns_to_use:
            return {"response": "éŒ¯èª¤ï¼šæä¾›çš„è³‡æ–™ä¸­ä¸åŒ…å«åˆ†ææ‰€éœ€çš„æ¬„ä½ã€‚", "status": "error"}

        filtered_df = analysis_data_df[columns_to_use].copy()
        
        # é‡æ–°å‘½åæ¬„ä½ä»¥ä¾¿æ–¼LLMç†è§£
        rename_map = {
            "å¸³è™Ÿåç¨±": "account_name", "é …ç›®": "category", "å“é …": "item_description",
            "ç™¼ç¥¨æ—¥æœŸ": "invoice_date", "ç™¼ç¥¨é‡‘é¡": "invoice_amount"
        }
        rename_map_existing = {k: v for k, v in rename_map.items() if k in filtered_df.columns}
        if rename_map_existing:
            filtered_df.rename(columns=rename_map_existing, inplace=True)

        # ç¢ºä¿é—œéµæ¬„ä½ç‚ºæ­£ç¢ºçš„æ•¸æ“šé¡å‹
        if 'invoice_amount' in filtered_df.columns:
            filtered_df['invoice_amount'] = pd.to_numeric(filtered_df['invoice_amount'], errors='coerce').fillna(0)
        if 'invoice_date' in filtered_df.columns:
            filtered_df['invoice_date'] = pd.to_datetime(filtered_df['invoice_date'], errors='coerce')

        logger.info(f"å·²æº–å‚™å¥½ {len(filtered_df)} ç­†æ•¸æ“šä¾› Agent åˆ†æã€‚")

        # å»ºç«‹ Pandas DataFrame Agent
        try:
            # æ­¥é©Ÿ 3a: ä½¿ç”¨ RAG å¾è²¡å‹™æŒ‡å—ä¸­ç²å–ç›¸é—œè³‡è¨Š
            financial_guide_query = f"é—œæ–¼ '{query}'ï¼Œè«‹æä¾›ç›¸é—œçš„è²¡å‹™æŒ‡æ¨™è¨ˆç®—èªªæ˜ã€‚"
            qa_response = await process_qa_query(platform, user_id, financial_guide_query)
            financial_definitions = qa_response['response'].split('---')[0].strip()
            
            if "ç³»çµ±å°šæœªæº–å‚™å¥½" in financial_definitions:
                logger.warning("ç„¡æ³•å¾ RAG ç²å–è²¡å‹™æŒ‡å—ï¼Œå°‡ä½¿ç”¨é è¨­æŒ‡å—ã€‚")
                financial_definitions = get_financial_definitions()
            else:
                logger.info("æˆåŠŸå¾ RAG ç²å–è²¡å‹™æŒ‡å—ã€‚")

            # æ­¥é©Ÿ 3b: å»ºç«‹ Agent
            # æ­¥é©Ÿ 3b: å»ºç«‹åŒ…å«è¨˜æ†¶çš„ Agent Prompt
            agent_prompt = ChatPromptTemplate.from_messages([
                ("system", SYSTEM_PROMPT),
                MessagesPlaceholder(variable_name="chat_history"),
                ("user", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ])

            # æ­¥é©Ÿ 3c: å»ºç«‹ Agent
            agent = create_pandas_dataframe_agent(
                self.llm,
                filtered_df,
                prompt=agent_prompt,
                verbose=True,
                agent_executor_kwargs={
                    "handle_parsing_errors": True,
                    "memory": memory
                },
                allow_dangerous_code=True
            )

            # æ­¥é©Ÿ 4: å»ºç«‹åŒ…å«å•†æ¥­è¦å‰‡å’ŒçŸ¥è­˜çš„æŸ¥è©¢
            qa_knowledge_section = ""
            if qa_knowledge:
                qa_knowledge_section = f"--- **æœƒè¨ˆå°ˆæ¥­çŸ¥è­˜** ---\n{qa_knowledge}\n"

            # enriched_query_old = (
            #     f"ç”¨æˆ¶å•é¡Œ: {query}\n\n"
            #     f"æ€è€ƒæ­¥é©Ÿ:\n"
            #     f"1. å¿«é€Ÿç†è§£å•é¡Œ: ç”¨æˆ¶æƒ³çŸ¥é“ '{query}'ã€‚æˆ‘éœ€è¦åˆ†æé€™å€‹å•é¡Œï¼Œä¸¦æ±ºå®šéœ€è¦å“ªäº›è¨ˆç®—æ­¥é©Ÿã€‚\n"
            #     f"2. å¿«é€Ÿç¯©é¸èˆ‡è¨ˆç®—: æ ¹æ“šã€å•†æ¥­è¦å‰‡ã€å’Œã€è²¡å‹™æŒ‡æ¨™è¨ˆç®—æŒ‡å—ã€ï¼ŒåŸ·è¡Œå¿…è¦çš„æ•¸æ“šç¯©é¸å’Œè¨ˆç®—ã€‚\n"
            #     f"3. å¿«é€Ÿç”Ÿæˆå ±å‘Š: æ ¹æ“šè¨ˆç®—çµæœï¼Œç”Ÿæˆä¸€ä»½ç”Ÿæˆå¥½è®€å¥½æ‡‚çš„è²¡å‹™å ±å‘Šã€‚\n\n"
            #     f"çŸ¥è­˜åº«:\n"
            #     f"--- å•†æ¥­è¦å‰‡ (æœ€é«˜å„ªå…ˆç´š) ---\n"
            #     f" - ç‡Ÿæ¥­æ”¶å…¥: category ç‚º 'æ”¶å…¥'ï¼Œä½†å‹™å¿…æª¢æŸ¥item_description ä¸åŒ…å«: 'è³‡æœ¬é¡', 'è‚¡æ±å¾€ä¾†', 'å€Ÿæ¬¾', 'åˆ©æ¯æ”¶å…¥'ç­‰éç‡Ÿæ¥­æ”¶å…¥ã€‚\n"
            #     f" - ç‡Ÿæ¥­è²»ç”¨: category ç‚º 'æ”¯å‡º'ã€‚\n"
            #     f"{qa_knowledge_section}"
            #     f"--- è²¡å‹™æŒ‡æ¨™è¨ˆç®—æŒ‡å— ---\n"
            #     f"{financial_definitions}\n"
            #     f"--- çŸ¥è­˜åº«çµæŸ ---\n"
            #     f"*å¿«é€Ÿå›æ‡‰å…§å®¹ï¼š**\n"
            #     f"å›æ‡‰é¿å…éæ–¼å‘†æ¿ï¼Œä½ æ˜¯å€‹æ´»ç”Ÿç”Ÿçš„è²¡å‹™åˆ†æå¸«\n"
            #     f"1. âœ¨æ ¸å¿ƒçµè«–ï¼šç”¨1-2å¥è©±ç¸½çµåˆ†æçµæœçš„æ ¸å¿ƒç™¼ç¾ã€‚\n"
            #     f"2. ğŸ“Šæ•¸æ“šåˆ†æï¼š1.æ¸…æ™°åœ°åˆ—å‡ºæ”¯æŒçµè«–çš„é—œéµæ•¸æ“šé»æˆ–è¨ˆç®—éç¨‹ã€‚\n2.å†è€ƒé‡è¦é€élineè¨Šæ¯é€²è¡Œå›è¦†ï¼Œè¡¨æ ¼ç”¨ markdown å‘ˆç¾ã€‚\n"
            #     f"3. ğŸ”å°ˆæ¥­æ´è¦‹ï¼šæ ¹æ“šåˆ†æçµæœï¼Œæä¾›1-2é»æœ‰åƒ¹å€¼çš„è²¡å‹™æ´è¦‹æˆ–å»ºè­°ã€‚\n"
            #     f"å‹™å¿…ç¢ºä¿ä½ æ‰€æœ‰å›æ‡‰çš„è«–é»çµæœæ˜¯ä¸€è‡´çš„ï¼Œé¿å…ä¸Šä¸‹æ–‡è«–é»ä¸ä¸€è‡´ã€‚\n"
            #     f"ç¾åœ¨ï¼Œè«‹æ ¹æ“šä»¥ä¸Šæ€è€ƒæ­¥é©Ÿå’ŒçŸ¥è­˜åº«ï¼ŒåŸ·è¡Œåˆ†æä¸¦å¿«é€Ÿå›ç­”ç”¨æˆ¶å•é¡Œã€‚"
            # )

            enriched_query = (
                f"å˜¿ï¼é€™æ˜¯æˆ‘çš„å•é¡Œï¼š\"{query}\"\n\n"
                f"è«‹ä½ ç”¨æˆ‘å€‘èªªå¥½çš„ã€Œè¦ªåˆ‡å¤¥ä¼´ã€é¢¨æ ¼ï¼Œå¹«æˆ‘çœ‹çœ‹æ•¸æ“šã€‚ä½ å¯ä»¥åƒè€ƒä¸‹é¢çš„å°ç­†è¨˜ï¼\n\n"
                f"--- çµ¦ä½ çš„å°ç­†è¨˜ ---\n"
                f"**å·¥å…·ä½¿ç”¨è¦å‰‡ (éå¸¸é‡è¦ï¼)**\n"
                f"ç•¶ä½ éœ€è¦ä½¿ç”¨ `python_repl_ast` å·¥å…·æ™‚ï¼Œä½ çš„ Action Input **åªèƒ½** åŒ…å«ä¸€è¡Œã€ç´”ç²¹çš„ Python ç¨‹å¼ç¢¼ï¼Œçµ•å°ä¸èƒ½æœ‰ä»»ä½•è¨»è§£æˆ–èªªæ˜æ–‡å­—ã€‚\n\n"
                f"**å•†æ¥­è¦å‰‡ (æœ€é«˜å„ªå…ˆç´š):**\n"
                f" - ç‡Ÿæ¥­æ”¶å…¥: category æ˜¯ 'æ”¶å…¥'ï¼Œä½†è¦å°å¿ƒ item_description ä¸èƒ½æ˜¯ 'è³‡æœ¬é¡', 'è‚¡æ±å¾€ä¾†', 'å€Ÿæ¬¾', 'åˆ©æ¯æ”¶å…¥' é€™äº›å–”ã€‚\n"
                f" - ç‡Ÿæ¥­è²»ç”¨: category æ˜¯ 'æ”¯å‡º'ã€‚\n"
                f"{qa_knowledge_section}"
                f"**è²¡å‹™æŒ‡æ¨™è¨ˆç®—æŒ‡å—:**\n"
                f"{financial_definitions}\n"
                f"--- å°ç­†è¨˜çµæŸ ---\n\n"
                f"å¥½äº†ï¼Œäº¤çµ¦ä½ äº†ï¼è«‹ç”¨ä½ çš„é­”æ³•ï¼Œå¹«æˆ‘è¼•é¬†åœ°è§£è®€é€™äº›æ•¸å­—å§ï¼è¨˜å¾—è¦æœ‰ âœ¨æ ¸å¿ƒäº®é»ã€ğŸ“Šæ•¸æ“šèŠä¸€èŠã€å’Œ ğŸ”ä¸€é»å»ºè­° å–”ï¼"
            )

            agent_result = await agent.ainvoke({
                "input": enriched_query,
                "chat_history": memory.chat_memory.messages
            })
            response_message += agent_result.get("output", "ç„¡æ³•ç²å–åˆ†æçµæœã€‚")

        except Exception as e:
            logger.error(f"Pandas Agent åŸ·è¡Œæˆ–å¾ŒçºŒè™•ç†å¤±æ•—: {e}", exc_info=True)
            status = "error"
            response_message = "æŠ±æ­‰ï¼Œä½¿ç”¨æ•¸æ“šåˆ†æä»£ç†æ™‚é‡åˆ°å•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        # ç¢ºä¿ duration ç¸½æ˜¯è¢«è¨ˆç®—
        duration = time.time() - start_time

        # åªæœ‰åœ¨æˆåŠŸæ™‚æ‰é™„åŠ æ•ˆèƒ½æŒ‡æ¨™
        if status == "success":
            performance_metrics = (
                f"\n\n---\n"
                f"*åˆ†æè€—æ™‚: {duration:.2f} ç§’*"
            )
            response_message += performance_metrics
        
        # æ›´æ–°æ—¥èªŒä¸­çš„ç¸½è€—æ™‚
        logger.info(f"å®Œæ•´è«‹æ±‚è™•ç†å®Œæˆï¼Œç¸½è€—æ™‚: {duration:.2f} ç§’ã€‚")
        
        return {
            "response": response_message, "status": status,
            "total_tokens": total_tokens, "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens, "duration": duration
        }

# å•Ÿå‹•æ™‚åˆå§‹åŒ–
def startup_finance_analysis_service():
    """æ‡‰ç”¨å•Ÿå‹•æ™‚çš„äº‹ä»¶è™•ç†"""
    logger.info("æ­£åœ¨å•Ÿå‹•è²¡å‹™åˆ†ææœå‹™...")
    logger.info("è²¡å‹™åˆ†ææœå‹™å•Ÿå‹•å®Œæˆã€‚")

# åœ¨æ¨¡å¡Šè¼‰å…¥æ™‚åŸ·è¡Œåˆå§‹åŒ–
startup_finance_analysis_service()

if __name__ == "__main__":
    async def interactive_session():
        """
        å•Ÿå‹•ä¸€å€‹äº’å‹•å¼æœƒè©±ï¼Œå…è¨±ç”¨æˆ¶åœ¨çµ‚ç«¯æ©Ÿä¸­ç›´æ¥èˆ‡è²¡å‹™åˆ†ææœå‹™é€²è¡Œå•ç­”ã€‚
        """
        processor = FinanceAnalysisProcessor()
        user_id = "local_terminal_user"
        platform = "terminal"
        logger.info("å•Ÿå‹•è²¡å‹™åˆ†æäº’å‹•æ¨¡å¼...")
        logger.info("æ‚¨å¯ä»¥é–‹å§‹æå•ï¼Œè¼¸å…¥ 'exit' æˆ–æŒ‰ä¸‹ Ctrl+C ä¾†çµæŸå°è©±ã€‚")

        while True:
            try:
                query = input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: ")
                if query.strip().lower() == 'exit':
                    logger.info("çµæŸå°è©±ã€‚")
                    break
                
                if not query.strip():
                    continue

                response = await processor.process_finance_query(platform, user_id, query)
                logger.info(f"å®Œæ•´å›æ‡‰: {response}")
                print(f"\nåˆ†æå¸«å›æ‡‰:\n{response['response']}\n")

            except (KeyboardInterrupt, EOFError):
                logger.info("\nåµæ¸¬åˆ°ä¸­æ–·ï¼ŒçµæŸå°è©±ã€‚")
                break
            except Exception as e:
                logger.error(f"åœ¨äº’å‹•æ¨¡å¼ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
                break

    asyncio.run(interactive_session())